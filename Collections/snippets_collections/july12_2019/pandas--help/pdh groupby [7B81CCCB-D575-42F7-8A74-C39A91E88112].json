{
  "alfredsnippet" : {
    "snippet" : "#==============================================================================\n\n# groupby attributes\nprint([attr for attr in dir(pd.core.groupby.groupby.DataFrameGroupBy) if not attr.startswith('_') ])\nprint([attr for attr in dir(pd.core.groupby.groupby.DataFrameGroupBy) if attr[0].islower() ])\n\n['agg', 'aggregate', 'all', 'any', 'apply', 'backfill', 'bfill', 'boxplot', 'corr', 'corrwith', 'count', 'cov', 'cumcount', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'dtypes', 'expanding', 'ffill', 'fillna', 'filter', 'first', 'get_group', 'groups', 'head', 'hist', 'idxmax', 'idxmin', 'indices', 'last', 'mad', 'max', 'mean', 'median', 'min', 'ndim', 'ngroup', 'ngroups', 'nth', 'nunique', 'ohlc', 'pad', 'pct_change', 'pipe', 'plot', 'prod', 'quantile', 'rank', 'resample', 'rolling', 'sem', 'shift', 'size', 'skew', 'std', 'sum', 'tail', 'take', 'transform', 'tshift', 'var']\n\n## example\n#******************************************************************************\ndf = pd.DataFrame({'A': [1, 1, 1, 2, 2],\n                   'B': [1, 1, 2, 2, 1],\n                   'C': [10, 20, 30, 40, 50],\n                   'D': ['X', 'Y', 'X', 'Y', 'Y']})\n\n# mean, sum, size, count, std, var, describe, first, last, nth, min, max\n# agg function: sem (standard error of mean of groups)\ndf.groupby(‘A’)[‘B’].count() # gives count of non-NaNs (use .size() to count NaNs)\ndf.groupby(‘A’)[‘B’].sum()   # gives series\ndf.groupby(‘A’)[[‘B’]].sum() # gives dataframe \ndf.groupby(‘A’, as_index=False)[‘B’].sum() # does not set index\ndf.groupby(‘A’, as_index=False).agg({‘B’: ‘sum’}) # gives columns A and B\ndf.groupby(‘A’)[‘B’].agg(lambda x: (x - x.mean()) \/ x.std() ) # zscore\ndf.groupby(‘D’).get_group(‘X’)                \ndf.groupby(‘A’).filter(lambda x: x > 1)\ndf.groupby(‘A’).describe()\ndf.groupby(‘A’).apply(lambda x: x *2)\ndf.groupby(‘A’).expanding().sum()\ndf.groupby('A')['B'].sum() # two rows with sum 6 and 9 (note cumsum() gives 5 rows)\ndf.groupby('A')['B'].transform('sum') # 5 rows, transform keeps same dimension.\ndf.transform({'A': np.sum, 'B': [lambda x : x+1, 'sqrt']})\n\n## add prefix\ndf.groupby('A').mean().add_prefix('mean_') # gives mean_B and mean_C, D is ignored.\ndf.groupby('A').max().add_suffix('_max')   # note: prefix, suffix accept ONLY ONE string.\n\n(df.groupby('A')\n    .agg({'B': 'sum', 'C': 'min'})\n    .rename(columns={'B': 'B_sum', 'C': 'C_min'})\n    .reset_index()\n)\n\n## multiple aggregation\ndf = pd.DataFrame({'A': [1, 1, 1, 2, 2],\n                   'B': [1, 2, 3, 2, 1],\n                   'C': [10, 20, 30, 40, 50]})\n\n### using reset to drop one level of multi-index\ng = (df.groupby('A') # agg gives here two rows of columns -- C,B and mean,count min,max and index A\n    .agg({'B': ['min', 'max'], 'C': ['mean','count']})\n    .reset_index()) # now index A, becomes first column with column name A, and its second level column name is empty.\n    \n### using as_index false to drop one level of multi-index (same as .reset_index())\ng = (df.groupby('A',as_index=False)\n    .agg({'B': ['min', 'max'], 'C': ['mean','count']}))\n\n#### rename columns\n### In above multiple aggregation examples, we get two levels of columns. (after reset or as_index = False)\n### To make only one column name, we can use list comprehension.\n### note: When we reset and make the index A, as column, it does not have second level column name.\ng.columns = ['_'.join(x).strip() if x[1] else x[0] for x in g.columns.ravel()]\n\n## Groupby with custom function\n#******************************************************************************\ndf = pd.DataFrame({'Name': list('ABCAB'),'Score': [20,40,80,70,90]})\ndef get_stats(group):\n    return {'min': group.min(), 'max': group.max(), 'count': group.count(), 'mean': group.mean()}\nbins = [0, 25, 50, 75, 100]\ngroup_names = ['Low', 'Okay', 'Good', 'Great']\ndf['categories'] = pd.cut(df['Score'], bins, labels=group_names)\ndf['Score'].groupby(df['categories']).apply(get_stats).unstack()\n\n## Groupby with pd.Grouper\n#******************************************************************************\ndf.groupby([pd.Grouper(freq='1M',key='Date'),'Buyer']).sum()\n\n## time series\n#******************************************************************************\ndf = pd.DataFrame({'date': pd.date_range(start='2016-01-01',periods=4,freq='W'),\n                   'group': [1, 1, 2, 2],\n                   'val': [5, 6, 7, 8]}).set_index('date') # only 4 rows\ndf.groupby('group').resample('1D').ffill() # 16 rows\n        \n\n## groupby with categorical data\npd.Series([1, 1, 1]).groupby(pd.Categorical(['a', 'a', 'a'],\n                        categories=['a', 'b']), observed=False).count()\n\n## pipe and apply\n(df.groupby(['A', 'B'])\n    .pipe(lambda grp: grp.C.max()) # .apply() gives same result.\n    .unstack().round(2))\n\n## using functions\ndef subtract_and_divide(x, sub, divide=1):\n    return (x - sub) \/ divide\n\ndf.iloc[:,:-1].apply(subtract_and_divide, args=(5,), divide=3)\n\n## groupby pipe (pipe is encourased to be used)\nf(g(h(df), arg1=1), arg2=2, arg3=3)\n(df.pipe(h)\n       .pipe(g, arg1=1)\n       .pipe(f, arg2=2, arg3=3)\n    )",
    "uid" : "7B81CCCB-D575-42F7-8A74-C39A91E88112",
    "name" : "pdh groupby",
    "keyword" : "pdh-groupby"
  }
}